{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox notebook\n",
    "\n",
    "This notebook contains examples on how to use scikit learn for forecasting.\n",
    "*Step* is set in the \"setup y and X\" cell, this lags all the independent X\n",
    "vars so that we are fiting for / predicting events y *step* time periods away\n",
    "*y_(t) = X_(t-step)*\n",
    "\n",
    "## Get started\n",
    "\n",
    "* File -> Make a copy\n",
    "* Set the *uname* to your database username\n",
    "* Run everything\n",
    "\n",
    "## What score?\n",
    "\n",
    "\"Estimator score method: Estimators have a score method providing a default evaluation criterion for the problem they are designed to solve. This is not discussed on this page, but in each estimatorâ€™s documentation.\"\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from views_utils import dbutils\n",
    "\n",
    "import nstep.utils\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Classifiers\n",
    "from sklearn import linear_model                        \n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "# Postprocessing\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS NEEDS CHANGING\n",
    "You need to set uname to your database username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = False\n",
    "CACHE_DATA = False\n",
    "run_id = \"sandbox\"\n",
    "uname = \"VIEWSADMIN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database parameters\n",
    "The default table launched.imp_imp_1 uses imputed y and X.\n",
    "Many of the derived variables are missing for this table. \n",
    "Feel free to use preflight.flight_pgm instead by changing input_schema and input_table.\n",
    "Remove your locally cahed dataframes in ~/data/df_train.hdf5 for the script to re-download. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db parameters\n",
    "prefix  = \"postgresql\"\n",
    "db      = \"views\"\n",
    "port    = \"5432\"\n",
    "hostname = \"VIEWSHOST\"\n",
    "\n",
    "input_schema    = \"launched\"\n",
    "input_table     = \"imp_imp_1\"\n",
    "output_schema   = \"landed_test\"\n",
    "output_table    = run_id\n",
    "\n",
    "timevar = \"month_id\"\n",
    "groupvar = \"pg_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time limits\n",
    "train_start = 300\n",
    "train_end = 408\n",
    "forecast_start = 409\n",
    "forecast_end = 444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varlists\n",
    "\n",
    "outcomes = [\"ged_dummy_sb\", \"ged_dummy_ns\", \"ged_dummy_os\"]\n",
    "features = [\"bdist3\", \n",
    "            \"ttime_mean\", \n",
    "            \"capdist\", \n",
    "            \"gcp_li_mer\", \n",
    "            \"imr_mean\", \n",
    "            \"mountains_mean\", \n",
    "            \"urban_ih_li\",  \n",
    "            \"agri_ih_li\", \n",
    "            \"barren_ih_li\",  \n",
    "            \"forest_ih_li\",  \n",
    "            \"savanna_ih_li\",  \n",
    "            \"shrub_ih_li\",  \n",
    "            \"pasture_ih_li\"]\n",
    "\n",
    "ids = [timevar, groupvar]\n",
    "columns_train = ids + outcomes + features\n",
    "columns_forecast = ids + outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data\n",
    "This cell fetches data from the database based on the varlists and time limits.\n",
    "If you change the features or time limits you need to manually delete your local copy of ~/data/df_train for the cell to re-fetch the table from the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didn't find the data on disk, getting from db instead\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'query_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a7659f7426ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/data/df_train.hdf5_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/data/df_test.hdf5_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise compat.FileNotFoundError(\n\u001b[0;32m--> 326\u001b[0;31m                 'File %s does not exist' % path_or_buf)\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File /Users/VIEWSADMIN/data/df_train.hdf5_ does not exist",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a7659f7426ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdbutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnectstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'query_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "\n",
    "# try reading cached\n",
    "try:\n",
    "    df_train = pd.read_hdf(os.path.expanduser(\"~/data/df_train.hdf5_\"))\n",
    "    df_test = pd.read_hdf(os.path.expanduser(\"~/data/df_test.hdf5_\")) \n",
    "    print(\"Got df_train and df_test from file\")\n",
    "# get from db if not cached\n",
    "except:\n",
    "    print(\"Didn't find the data on disk, getting from db instead\")\n",
    "\n",
    "    connectstring = dbutils.make_connectstring(prefix, db, uname, hostname, port)\n",
    "\n",
    "    query_train = dbutils.make_select_limited(\n",
    "        schema=input_schema, \n",
    "        table=input_table, \n",
    "        columns=columns_train, \n",
    "        timevar=timevar, \n",
    "        tmin=train_start, \n",
    "        tmax=train_end\n",
    "        )\n",
    "\n",
    "    query_forecast = dbutils.make_select_limited(\n",
    "        schema=input_schema, \n",
    "        table=input_table, \n",
    "        columns=columns_forecast, \n",
    "        timevar=timevar, \n",
    "        tmin=forecast_start, \n",
    "        tmax=forecast_end\n",
    "        )\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"Getting data\")\n",
    "        print(query_train)\n",
    "\n",
    "    df_train = dbutils.query_to_df(connectstring, query_train, \n",
    "        verbose=False, chunksize=100000)\n",
    "    df_train.set_index(ids, inplace=True)\n",
    "    df_train.sort_index(inplace=True)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(query_test)\n",
    "    \n",
    "    df_test = dbutils.query_to_df(connectstring, query_test, verbose=False, chunksize=100000)\n",
    "    df_test.set_index(ids, inplace=True)\n",
    "\n",
    "    if CACHE_DATA:\n",
    "        df_train.to_hdf(os.path.expanduser(\"~/data/df_train.hdf5\"), key='data')\n",
    "        df_test.to_hdf(os.path.expanduser(\"~/data/df_test.hdf5\"), key='data')\n",
    "\n",
    "    print(\"Got df_train and df_test from db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast step\n",
    "This cell does the lagging of the right handside/X/features\n",
    "\n",
    "Change the value of *step* to tweak this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1c4d04415447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# y_t, X_(t-step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_y_X_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare_zeros_keep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mshare_zeros_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup y and X with:\n",
    "# Shifting X by step to provide a \"forecasting\" effect\n",
    "step = 36\n",
    "# Downsampling \n",
    "outcome = \"ged_dummy_sb\"\n",
    "share_zeros_keep = 0.1\n",
    "\n",
    "# y_t, X_(t-step)\n",
    "y, X = nstep.utils.get_y_X_step(df_train, step, outcome, features, share_zeros_keep)\n",
    "\n",
    "share_zeros_keep = 1\n",
    "y_full, X_full = nstep.utils.get_y_X_step(df_train, step, outcome, features, share_zeros_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit examples\n",
    "The following cells show how to fit and predict using scikit. \n",
    "Starting with just a classifier we add scaling of inputs, hyperparameter tuning and finally calibration of predict probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precrec(y_test, y_pred):\n",
    "    average_precision = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                     color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(\n",
    "              average_precision))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single random split train test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Our Multi Layer Perceptron (chosen for fancy name)\n",
    "mlp =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1, verbose=True)\n",
    "\n",
    "# Fit our classifier\n",
    "mlp.fit(X_train, y_train)\n",
    "# Accuracy score\n",
    "score = mlp.score(X_test, y_test)\n",
    "print(\"Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single random split train test with input scaling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "# Our Multi Layer Perceptron (chosen for fancy name)\n",
    "mlp =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1, verbose=True)\n",
    "\n",
    "# Scales an input matrix to mean 0 stdev 1\n",
    "scaler =  StandardScaler()\n",
    "# Fit the scaler, this defines the scaling transformation so we can scale X_test the same way\n",
    "scaler.fit(X_train)\n",
    "# Apply the scaling transformation to X\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit our classifier\n",
    "mlp.fit(X_train, y_train)\n",
    "# Accuracy score\n",
    "score = mlp.score(X_test, y_test)\n",
    "print(\"Score:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline example with random split\n",
    "# notice exact same score as cell above\n",
    "# pipeline does the fit and transform for us.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "mlp =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1, verbose=True)\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "# The pipeline combines the scaler and mlp to a single coherent classifier\n",
    "clf = make_pipeline(scaler, mlp)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold Cross validation score with a pipeline\n",
    "\n",
    "mlp =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1, verbose=True)\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "clf = make_pipeline(scaler, mlp)\n",
    "cv_scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"Scores:\")\n",
    "for score in cv_scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified K-fold, each set gets approx same amount of y=1's\n",
    "\n",
    "mlp =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1, verbose=True)\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "clf = make_pipeline(scaler, mlp)\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "print(\"Stratified K-Fold Scores:\")\n",
    "print(\"k=\", )\n",
    "for train, test in skf.split(X, y):\n",
    "    clf.fit(X[train], y[train])\n",
    "    score = clf.score(X[test], y[test])\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhaustive grid search for hyperparameter tuning\n",
    "# This loops over all the combinations of parameters and performs K-fold cross validation\n",
    "# The best parameters are found and printed\n",
    "\n",
    "mlp =  MLPClassifier(random_state=1)\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "# Syntax is pipelinecomponent__parameter, notice double underscores\n",
    "# Parameters to try are given as tuples\n",
    "parameters = {\n",
    "    'mlp__hidden_layer_sizes' : ((5,5), (10,5), (5,5,5)),\n",
    "    'mlp__solver' : ('lbfgs', 'sgd', 'adam'),\n",
    "    'mlp__alpha' : (1e-3, 1e-5, 1e-7)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('mlp', mlp)\n",
    "])\n",
    "\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "\n",
    "K = 3\n",
    "cpu_cores = 2\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, verbose=1, cv=K, n_jobs=cpu_cores)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best score: %0.5f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "y_pred = grid_search.predict(X_full)\n",
    "plot_precrec(y_full, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exhaustive grid search for hyperparameter tuning, Random Forest Example\n",
    "# This loops over all the combinations of parameters and performs K-fold cross validation\n",
    "\n",
    "rf =  RandomForestClassifier()\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "# Syntax is pipelinecomponent__parameter, notice double underscores\n",
    "parameters = {\n",
    "    'rf__n_estimators' : (5, 15, 35)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "\n",
    "K = 3\n",
    "cpu_cores = 2\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, verbose=1, cv=K, n_jobs=cpu_cores)\n",
    "grid_search.fit(X, y)\n",
    "y_pred = grid_search.predict(X_full)\n",
    "\n",
    "print(\"Best score: %0.5f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "plot_precrec(y_full, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch with StratifiedKFold on  K neighbors classifier\n",
    "# Principle Component Analysis (PCA) is included, are all the features useful?\n",
    "\n",
    "scaler =  StandardScaler()\n",
    "pca = PCA()\n",
    "knc =  KNeighborsClassifier()\n",
    "K_splits = 3\n",
    "skf = StratifiedKFold(n_splits = K_splits)\n",
    "\n",
    "# Syntax is pipelinecomponent__parameter, notice double underscores\n",
    "parameters = {\n",
    "    'knc__n_neighbors' : (1,3,5,15,30),\n",
    "    'pca__n_components' : (1,2,3,4,5,6,7,8)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('pca', pca),\n",
    "    ('knc', knc)\n",
    "])\n",
    "\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "\n",
    "cpu_cores = 2\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, verbose=1, cv=skf, n_jobs=cpu_cores)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "clf_best = grid_search.best_estimator_\n",
    "df_gs_resuls = pd.DataFrame(grid_search.cv_results_)\n",
    "print(\"Best score: %0.5f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "print(df_gs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "Scikit has a method for calibrating classifiers called CalibratedClassifierCV, which uses a sigmoid.\n",
    "\n",
    "Another option is doing it manually, by fitting a logistic regression of the predicted probabilities from the uncalibrated model on the actual outcomes. \n",
    "\n",
    "Note that I'm not using a separate calibration set, just the non-downsampledtrainingdata, so don't follow my example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First a pipeline with a StandardScaler and an MLPClassifier are trained on downsampled data (X).\n",
    "# Then a CalibratedClassifierCV (cc) object based on the pipeline is fited on the full training data.\n",
    "\n",
    "# These are downsampled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Train clf on downsampled\n",
    "mlp =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1, verbose=True)\n",
    "scaler =  StandardScaler()\n",
    "clf = make_pipeline(scaler, mlp)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Calibrate the classifier on full data\n",
    "cc = CalibratedClassifierCV(clf, cv='prefit')\n",
    "cc.fit(X_full, y_full)\n",
    "\n",
    "\n",
    "# predict probabilities and calibrated probabilities from full data\n",
    "p_y = clf.predict_proba(X_full)\n",
    "p_y_calib = cc.predict_proba(X_full)\n",
    "\n",
    "\n",
    "# predict_proba gives one columns for each class in our data, \n",
    "# for our binary case we have two classes, y=0 and y=1. \n",
    "# p_y[:,0] gives probs of y=0\n",
    "# p_y[:,1] gives probs of y=1\n",
    "# p_1 is prob zero, pc_1 is calibrated prob zero\n",
    "df_p = pd.DataFrame({\n",
    "    'p_0' : p_y[:,0],\n",
    "    'p_1' : p_y[:,1],\n",
    "    'pc_0' : p_y_calib[:,0],\n",
    "    'pc_1' : p_y_calib[:,1]})\n",
    "print(\"Pay attention to the axes limits!\")\n",
    "df_p.plot(kind='scatter', x='p_0', y='pc_0', title=\"Raw vs calibrated p(y=0)\")\n",
    "df_p.plot(kind='scatter', x='p_1', y='pc_1', title=\"Raw vs calibrated p(y=1)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First a pipeline with a StandardScaler and an MLPClassifier are trained on downsampled data (X).\n",
    "# Then a CalibratedClassifierCV (cc) object based on the pipeline is fited on the full training data.\n",
    "# The cc uses a sigmoid (logit-style) by default\n",
    "\n",
    "# These are downsampled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "# Train clf on downsampled\n",
    "mlp =  MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(10, 5), random_state=1, verbose=True)\n",
    "scaler =  StandardScaler()\n",
    "clf = make_pipeline(scaler, mlp)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict probabilities on full data\n",
    "p_y = clf.predict_proba(X_full)\n",
    "\n",
    "# Train a logit model \n",
    "# y_actual = alpha + beta * p_y \n",
    "# where p_y is uncalibrated probs\n",
    "logit = LogisticRegression()\n",
    "logit.fit(p_y[:,1].reshape(-1, 1), y_full)\n",
    "p_y_calib = logit.predict_proba(p_y[:,1].reshape(-1, 1))\n",
    "\n",
    "# p_1 is prob zero, pc_1 is calibrated prob zero\n",
    "df_p = pd.DataFrame({\n",
    "    'p_0' : p_y[:,0],\n",
    "    'p_1' : p_y[:,1],\n",
    "    'pc_0' : p_y_calib[:,0],\n",
    "    'pc_1' : p_y_calib[:,1]})\n",
    "print(\"Pay attention to the axes limits!\")\n",
    "df_p.plot(kind='scatter', x='p_0', y='pc_0', title=\"Raw vs calibrated p(y=0)\")\n",
    "df_p.plot(kind='scatter', x='p_1', y='pc_1', title=\"Raw vs calibrated p(y=1)\")\n",
    "plt.show()\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'actual' : y_full,\n",
    "    'p' : p_y[:,1],\n",
    "    'pc' : p_y_calib[:,1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['error_raw'] = df_test['actual'] - df_test['p']\n",
    "df_test['error_calib'] = df_test['actual'] - df_test['pc']\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"raw error\")\n",
    "df_test['error_raw'].hist(bins=100)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.title(\"calibrated error\")\n",
    "df_test['error_calib'].hist(bins=100)\n",
    "plt.show()\n",
    "print(df_test.describe())\n",
    "\n",
    "avg_precision_raw = average_precision_score(df_test['actual'], df_test['p'])\n",
    "avg_precision_calib = average_precision_score(df_test['actual'], df_test['pc'])\n",
    "\n",
    "print(\"precision raw:  \", avg_precision_raw)\n",
    "print(\"precision calib:\", avg_precision_calib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statsmodels\n",
    "The cells below show some statsmodels examples\n",
    "\n",
    "Note that THESE ARE NOT FORECASTING! \n",
    "\n",
    "Models are y_t = beta*X_t\n",
    "\n",
    "Todo:\n",
    "In the get_y_X_step() function I should add an option for getting lagged groups also"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS PREDICTING y_t with X_t NOT FORECASTING!\n",
    "# Random effects\n",
    "df_re = df_train.sample(n=1000000)\n",
    "formula_sm = \"ged_dummy_sb ~ bdist3 + ttime_mean + capdist + gcp_li_mer + imr_mean + mountains_mean + urban_ih_li + agri_ih_li + barren_ih_li + forest_ih_li + savanna_ih_li + shrub_ih_li + pasture_ih_li\"\n",
    "# get_level_values(1) gives the values of pg_id because df has had set_index(['month_id', 'pg_id'])\n",
    "md = smf.mixedlm(formula_sm, df_re, groups=df_re.index.get_level_values(1))\n",
    "mdf = md.fit()\n",
    "print(mdf.summary())\n",
    "df_re['pred_y'] = mdf.predict()\n",
    "df_re['error'] = df_re['pred_y'] - df_re['ged_dummy_sb']\n",
    "df_re[['ged_dummy_sb', 'pred_y', 'error']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
