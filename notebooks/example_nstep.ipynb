{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-STEP demo\n",
    "\n",
    "## Quickstart:\n",
    "\n",
    "* Change uname to your db username\n",
    "* Run all the cells\n",
    "* Make coffee\n",
    "* Check the table landed_test.nstep_notebook in the database\n",
    "\n",
    "## Overview\n",
    "This notebook contains an example of how to use the N-step ahead forecasting tools.\n",
    "The models are terrible, they are just an illustration. \n",
    "Everything is based around the model dictionaries. \n",
    "\n",
    "A model dictionary contains all the information of a forecast:\n",
    "\n",
    "* outcome\n",
    "* list of features\n",
    "* estimator object (Usually a scikit Pipeline)\n",
    "* time limits for training and forecasting\n",
    "* which time steps to forecast for\n",
    "* which input table to use\n",
    "* downsampling factors for y=1 and y=0\n",
    "\n",
    "The nstep.forecast_many() method is the key component:\n",
    "given a list of model dictionaries it returns a dataframe of forecasted values.\n",
    "\n",
    "\n",
    "It does:\n",
    "\n",
    "* Reading from database\n",
    "* Fitting the model for each step\n",
    "* Forecasting for each step, both predicted probs and predicted outcomes (discrete)\n",
    "* Interpolate between the steps\n",
    "* Merging the forecast of many models to one dataframe\n",
    "\n",
    "For each model 5 columns go into the database\n",
    "\n",
    "* actual_model : The actual value of the outcome\n",
    "* model : predicted value from the model, usually binary (predict())\n",
    "* p_model : predicted probability (predict_proba())\n",
    "* model_li : linear interpolation of predicted value\n",
    "* p_model_li : linear prediction of predicted probability\n",
    "\n",
    "The last cell then writes these predictions to the specified output table using \n",
    "dbutils.df_to_db().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import views_utils.dbutils as dbutils\n",
    "import nstep.utils as nstep\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db parameters\n",
    "uname    = \"VIEWSADMIN\"\n",
    "prefix   = \"postgresql\"\n",
    "db       = \"views\"\n",
    "port     = \"5432\"\n",
    "hostname = \"VIEWSHOST\"\n",
    "connectstring = dbutils.make_connectstring(prefix, db, uname, hostname, port)\n",
    "\n",
    "output_schema   = \"landed_test\"\n",
    "output_table    = \"nstep_example\"\n",
    "\n",
    "# specify as many as you want\n",
    "table_input = {\n",
    "    'connectstring' : connectstring,\n",
    "    'schema'    : 'launched',\n",
    "    'table'     : 'imp_imp_1',\n",
    "    'timevar'   : 'month_id',\n",
    "    'groupvar'  : 'pg_id'\n",
    "}\n",
    "\n",
    "table_input_noimp = {\n",
    "    'connectstring' : connectstring,\n",
    "    'schema'    : 'preflight',\n",
    "    'table'     : 'flight_pgm',\n",
    "    'timevar'   : 'month_id',\n",
    "    'groupvar'  : 'pg_id'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember all X are lagged by step, outcomes can be features \n",
    "features_mini = [    \n",
    "    \"ged_dummy_sb\",\n",
    "    \"ged_dummy_ns\",\n",
    "    \"ged_dummy_os\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLPC\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', MLPClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'mlp__hidden_layer_sizes' : ((50,)),\n",
    "    'mlp__solver' : ('lbfgs', 'adam'),\n",
    "    'mlp__alpha' : (1e-3, 1e-7)\n",
    "}\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    pipeline, \n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3, \n",
    "    n_jobs=2)\n",
    "\n",
    "model_mlpc= { \n",
    "        'name'      : 'mlp',\n",
    "        'outcome'   : 'ged_dummy_sb',\n",
    "        'estimator' : gscv,\n",
    "        'features'  : features_mini,\n",
    "        'steps'     : [1,36],\n",
    "        'share_zeros_keep'  : 0.1,\n",
    "        'share_ones_keep'   : 0.1,\n",
    "        'train_start'   : 300,\n",
    "        'train_end'     : 408,\n",
    "        'forecast_start': 409,\n",
    "        'forecast_end'  : 444,\n",
    "        'table' : table_input\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "rf =  RandomForestClassifier()\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "# Syntax is pipelinecomponent__parameter, notice double underscores\n",
    "params = {\n",
    "    'rf__n_estimators' : (1, 2, 3, 4, 5, 6)\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "gscv = GridSearchCV(\n",
    "    pipeline, \n",
    "    params, \n",
    "    verbose=1, \n",
    "    cv=3, \n",
    "    n_jobs=2)\n",
    "\n",
    "model_rf = { \n",
    "        'name'      : 'rf',\n",
    "        'outcome'   : 'ged_dummy_sb',\n",
    "        'estimator' : gscv,\n",
    "        'features'  : features_mini,\n",
    "        'steps'     : [1, 12, 24, 36],\n",
    "        'share_zeros_keep'  : 0.5,\n",
    "        'share_ones_keep'   : 0.5,\n",
    "        'train_start'   : 300,\n",
    "        'train_end'     : 408,\n",
    "        'forecast_start': 409,\n",
    "        'forecast_end'  : 444,\n",
    "        'table' : table_input\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting forecast mlp\n",
      "Getting 6 cols from launched.imp_imp_1\n",
      "Getting 3 cols from launched.imp_imp_1\n",
      "Training mlp step 1\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('mlp', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rat...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'mlp__hidden_layer_sizes': (50,), 'mlp__solver': ('lbfgs', 'adam'), 'mlp__alpha': (0.001, 1e-07)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VIEWSADMIN/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mlp step 36\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  12 out of  12 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('mlp', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rat...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'mlp__hidden_layer_sizes': (50,), 'mlp__solver': ('lbfgs', 'adam'), 'mlp__alpha': (0.001, 1e-07)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VIEWSADMIN/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished forecasting mlp\n",
      "Starting forecast rf\n",
      "Getting 6 cols from launched.imp_imp_1\n",
      "Getting 3 cols from launched.imp_imp_1\n",
      "Training rf step 1\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'rf__n_estimators': (1, 2, 3, 4, 5, 6)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VIEWSADMIN/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rf step 12\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'rf__n_estimators': (1, 2, 3, 4, 5, 6)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=1)\n",
      "Training rf step 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VIEWSADMIN/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'rf__n_estimators': (1, 2, 3, 4, 5, 6)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=1)\n",
      "Training rf step 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/VIEWSADMIN/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:    3.4s finished\n",
      "/Users/VIEWSADMIN/miniconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, error_score='raise',\n",
      "       estimator=Pipeline(memory=None,\n",
      "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "      ...n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False))]),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'rf__n_estimators': (1, 2, 3, 4, 5, 6)},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=1)\n",
      "Finished forecasting rf\n"
     ]
    }
   ],
   "source": [
    "# Forecast the models\n",
    "models = [model_mlpc, model_rf]\n",
    "df_results = nstep.forecast_many(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing 384372 rows to landed_test.nstep_example\n",
      "\u001b[92m [OK] \u001b[0m\n",
      "runtime:  395.04440784454346 rows/second:  972.984283203059\n"
     ]
    }
   ],
   "source": [
    "# Write forecast to db\n",
    "dbutils.df_to_db(connectstring, df_results, output_schema, output_table, \n",
    "    if_exists=\"replace\", write_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
